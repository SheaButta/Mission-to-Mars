# Mission-to-Mars

## Overview of Project

### Purpose
The purpose of this project was to assist an analyst scrape data from a Mars NASA and Mars Hemisphere websites.  To complete this task, I used several development tools to extract, transform and load the data into a local MongoDB database.  Once the data was ETL process was completed, I used Flask, HTML, JavaScript and BootStrap to visualize the data and images on a website.  The standard data analysis principles were used which includes; (1) Determine the number of rows and columns in the data; (2) Data types used; and (3) Is the data readable?

__Requirements for Project__
- Extract, Transform
- Load data into MongoDB
- Visualize using Flask

## Resources

- Pandas
- HTML/JavaScript
- Flask
- Splinter
- Beautiful Soup
- Visual Studio
- MongoDB

  
## Results
Successfully stored mars fact data in MongoDB and visualized using Flask.  The fact table image was updated using Bootstrap.
![Mars Fact Table](https://github.com/SheaButta/Mission-to-Mars/blob/main/images/Mars_factsheet_table.PNG)

Successfully stored mars hemisphere data in MongoDB and visualized using Flask.  This image was updated using Bootstrap.
![Mars Hemispheres](https://github.com/SheaButta/Mission-to-Mars/blob/main/images/Mars_hemisphere_Images.PNG)


## Summary
Although scrapting data can get a bit complex, the results were very benefical to the analyst I assisted. With web scraping and Mongo in my arsenal, I can can easily work with structed/unstructed data using most database environments in the cloud or on-prem.  


![](https://github.com/SheaButta/Mission-to-Mars/blob/main/images/Mission-to-Mars_title.PNG)

 
    
 
 
 
 
 
